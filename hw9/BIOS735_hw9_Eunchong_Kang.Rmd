---
title: "HW 9 - MCMC"
author: "Eunchong Kang"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output: html_document
editor_options: 
  chunk_output_type: console
---
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




# Maximization of poisson GLMM from lecture


Given the alzheimer data, maximize the poisson GLMM model by using an MCEM approach and a Metropolis Hastings Random Walk proposal distribution.

Specify your proposal distribution.  Write functions implementing the E-step, the M-step, and then write the main code for the MCEM algorithm.  


The function to be maximized is below.
$$L(\boldsymbol{\beta}, \sigma^2_{\gamma} | y) = \prod_{i = 1}^{22}\int \left[\left(\prod_{j = 1}^{5}f(y_{ij} | \lambda_{ij})\right)\phi(\gamma_i| 0, \sigma^2_{\gamma}) \right] d\gamma_i$$

Here, $\gamma_i$ is the random effect with the distribution of $N(0, \sigma^2_{\gamma})$. 

The $Q$ function is below.

\begin{align}
Q_i(\boldsymbol{\theta}|\boldsymbol{\theta}^{(t)}) &= \int \left[\log (f(\boldsymbol{y}_{i} | \boldsymbol{\lambda}_{i}) + \log\left(\phi(\boldsymbol{\gamma}_i| 0, \sigma^2_{\gamma})\right)\right]f(\boldsymbol{\gamma}_i | \boldsymbol{y}_o, \boldsymbol{\theta}^{(t)})d\boldsymbol{\gamma}_i\\
&= \int \left[\sum_{j = 1}^{5}\log(f(y_{ij} | \lambda_{ij}) + \log\left(\phi(\boldsymbol{\gamma}_i| 0, \sigma^2_{\gamma})\right)\right]f(\boldsymbol{\gamma}_i | \boldsymbol{y}_o, \boldsymbol{\theta}^{(t)})d\boldsymbol{\gamma}_i\\
&\approx \frac{1}{M}\sum_{k = 1}^M\left[\sum_{j = 1}^{5}\log\left(f(y_{ij} | \lambda_{ijk})\right) + \log\left(\phi(X_k| 0, \sigma^2_{\gamma})\right)\right]
\end{align}

For this homework, E-step is to approximate the $Q$ function, and M-step is to maximize the $Q$ function given the alzheimer data.  

The proposal distribution for MH algorithm with random walk chain is the normal distribution with $\mu=0$ and $\sigma=0.3$ to make acceptance rate close to 44% and between 25~50%


## 1. Import Data
```{r}
# Import data
setwd("D:/Spring_2022_D/BIOS735/hw/hw9")
alz = read.table("alzheimers.dat", header = T)
```
  

## 2. Helper Function for the E-step
2-1. 'F' function is the function for the log likelihood for ith subject  
2-2. 'h.sim' function is Proposal density for RW chain  
2-3. 'R' function is MH ratio function for RW chain  
2-4. 'mwg.rw.sampler ' function is RW sampler  
```{r}
# 2-1. function for the log likelihood for ith subject, x is the proposal or current value for gammai
f <- function(x, yi, Xi, betat, s2gammat) {
        # calculate lambdai
        lambdai <- exp(Xi %*% betat + x)
        
        # sum across repeated observations for poisson portion
        lli <- sum(dpois(yi, lambdai, log = T))
        
        # dont forget to include the MVN log likelihood
        lli <- lli  + dnorm(x, sd = sqrt(s2gammat), log = T)
        
        return(lli)
}

# 2-2. Proposal density for RW chain
h.sim <- function() {
        rnorm(1, sd=0.3)
}


# 2-3. MH ratio function for RW chain
R <- function(xt, x, f, yi, Xi, betat, s2gammat) {
        # log numerator - log denominator
        logR <- f(x, yi, Xi, betat, s2gammat) - f(xt, yi, Xi, betat, s2gammat)
        R <- exp(logR)
        return(R)
}

# 2-4. RW sampler
# Output: gammai is a chain
mwg.rw.sampler <- function(yi, Xi, betat, s2gammat, M, prev.gamma.i = NULL) {
        # initialize the chain vector
        # Empty vector
        x.indep.chain <- rep(0, M)
        
        if (is.null(prev.gamma.i)) {
                # Simulate initial draw from "original proposal density g"
                x.indep.chain[1] <- rnorm(1, sd=sqrt(s2gammat))
        } else{
                # if last value from previous chain avail, start there
                x.indep.chain[1] <- prev.gamma.i
        }
        
        # now start chain
        accept <- 0
        for (i in 1:(M - 1)) {
                # set the value at current iteration of the chain to variable xt
                xt <- x.indep.chain[i]
                
                # draw a proposal from the proposal density
                x <- xt + h.sim()
                
                # calculate MH ratio
                r <- min(R(xt, x, f, yi, Xi, betat, s2gammat), 1)
                
                # Generate draw from bernoulli(p).
                keep <- rbinom(1, 1, r)
                
                if (keep == 1) {
                        # if keep = 1, then set next iteration equal to then proposal
                        x.indep.chain[i + 1] <- x
                        #  update number of acceptacnes
                        accept = accept + 1
                } else{
                        # otherwise, carry over value from the current iteration
                        x.indep.chain[i + 1] <- xt
                }
        }
        
        return(list(gammai = x.indep.chain, ar = accept / M))
}
```



## 3. E-step function
3. 'e.step' function is to approximate the $Q$ function.

```{r}
# 3. E step function
e.step <- function(y, X, ID, betat, s2gammat, M, n, ni, sampler, burn.in = 2000, prev.gamma = NULL) {
        # initialize Q-function
        Qfunction <- 0
        
        # vector to hold chains from each subject
        gamma <- rep(0, n * M)
        
        # vector to hold subject acceptance rates
        ar <- rep(0, n)
        
        # vector to hold offset values Zi %*% gammai, yaug, Xaug in M step
        N <- ni * n
        offset <- yaug <- rep(0, N * M)
        Xaug <- matrix(0, nrow = N * M, ncol = ncol(X))
        
        # loop over observations
        for (i in 1:n) {
                # subject i indices
                subjecti <- which(ID == i)
                
                # grab subject i data
                yi <- y[subjecti]
                Xi <- X[subjecti, ]
                
                # create chain of length M per observation
                if (is.null(prev.gamma)) {
                        # if no previous chain available
                        # start from scratch and remove burn.in
                        chain <- sampler(
                                yi = yi,
                                Xi = Xi,
                                betat = betat,
                                s2gammat = s2gammat,
                                M = M + burn.in
                        )
                        gammai = chain$gammai[-c(1:burn.in)]
                } else{
                        # if chain available from previous EM
                        # restart this chain from last draw in previous chain
                        chain = sampler(
                                yi = yi,
                                Xi = Xi,
                                betat = betat,
                                s2gammat = s2gammat,
                                M = M,
                                # no burn in
                                prev.gamma = prev.gamma[i]
                        )
                        gammai = chain$gammai
                }
                
                ar[i] <- chain$ar
                
                # create augmented versions for Q function calculation
                # total length is (n*ni*M) rows
                aug <- rep(1:ni, M)
                yi_aug <- yi[aug]
                Xi_aug <- Xi[aug, ]
                Zi_aug <- Xi_aug[,1]
                
                # create augmented version of gammai to aid vectorization
                # repeated ni times per replicated subject
                # total length is (n*ni*M) rows
                augg <- rep(1:M, each = ni)
                gammai_aug <- gammai[augg]
                
                # calculate Q function for subject i:  poisson portion (n*ni*M)
                XBaug <- Xi_aug %*% betat
                # Zgammaaug = gammai_aug
                Zgammaaug <- Zi_aug * gammai_aug
                lambdai_aug <- exp(XBaug + Zgammaaug)
                Qi <- sum(dpois(yi_aug, lambda = lambdai_aug, log = T))
                
                # calculate Q function for subject i:  MVN portion (n*M)
                Qi <- Qi + sum(dnorm(gammai_aug, sd = sqrt(s2gammat), log = T))
                
                # divide by M
                Qi <- Qi / M
                
                # add to overall Q estimate
                Qfunction <- Qfunction + Qi
                
                # save offset, yaug, xaug for later
                a <- (i - 1) * M * ni + 1
                b <- i * M * ni
                offset[a:b] <- Zgammaaug
                yaug[a:b] <- yi_aug
                Xaug[a:b, ] <- Xi_aug
                
                # save gammai for later
                a <- (i - 1) * M + 1
                b <- i * M
                gamma[a:b] <- gammai
        }
        
        return(
                list(
                        Qfunction = Qfunction,
                        gamma = gamma,
                        ar = ar,
                        offset = offset,
                        yaug = yaug,
                        Xaug = Xaug
                )
        )
}
```

## 4. Set-up for Iteration

```{r}
# N: Total number of observations
N <- nrow(alz)

# alz_mat: 1th col-subject, 2th-month, 3th-words
alz_mat <- as.matrix(alz)

# y: words
y <- alz_mat[,3]

# ID: subject vector for each observation
ID <- alz_mat[,1]

# X: Matrix for fixed effects
X <- cbind(rep(1, N), alz_mat[,2])

# n: The number of subjects
n <-  length(unique(alz$subject))

# ni: The number of measurements
ni <- 5

## set initial parameters
tol = 10^-5
maxit = 100
iter = 0
eps = Inf
qfunction = -10000 # using Qfunction for convergence
prev.gamma = NULL
  

# starting values, taken from rejection sampling example
beta = c(1.804, 0.165) 
s2gamma =  0.000225 + .01


# Length of chain
M = 10000
# burn in: default is 2000
# burn.in = 2000
```


## 5. Iteration

```{r}
start = Sys.time()
while(eps > tol & iter < maxit) {
        ## save old qfunction
        qfunction0 <- qfunction
        
        ## obtain last chain value (Mth value) for each obs if iter > 0
        if (iter > 0) {
                prev.gamma <- gamma[seq(M, length(gamma), by = M)]
        }
        
        ## E-step
        estep <- e.step(
                y = y,
                X = X,
                ID = ID,
                betat = beta,
                s2gammat = s2gamma,
                M = M,
                n = n,
                ni = ni,
                sampler = mwg.rw.sampler,
                prev.gamma = prev.gamma
        )
        gamma <- estep$gamma
        qfunction <- estep$Qfunction
        offset <- estep$offset
        yaug <- estep$yaug
        Xaug <- estep$Xaug
        
        ## Calculate relative change in qfunction from prior iteration
        eps  = abs(qfunction - qfunction0) / abs(qfunction0)
        
        ## Start M-step
        
        # s2gamma, MLE for sigma^2 from normal with mean 0, averaged over M
        # closed form derived from Q function approximation
        s2gamma = sum(gamma * gamma) / (n * M)
        
        aug = rep(1:n, each = M)
        fit = glm(
                yaug ~ Xaug - 1,
                family = poisson(),
                weights = rep(1 / M, nrow(Xaug)),
                offset = offset,
                # use starting value from previous step
                start = beta
        )
        beta = as.vector(fit$coefficients)
        
        ## update iterator
        iter = iter + 1
        if (iter == maxit)
                warning("Iteration limit reached without convergence")
        
        ## print out info to keep track
        cat(
                sprintf(
                        "Iter: %d Qf: %.3f s2gamma: %f beta0: %.3f beta1:%.3f eps:%f\n",
                        iter,
                        qfunction,
                        s2gamma,
                        beta[1],
                        beta[2],
                        eps
                )
        )
}
end = Sys.time()
print(end - start
)
```

+ Comment: I found the $Q$ function is not strictly decreasing. It is more likely that my code is wrong, but I think this could be possible even when the code is right because MCMC is the approximation of the target function and the tolerance is too small ??


## 6. Chain Diagnostics

```{r}
# The Vector of Acceptance rate
estep$ar

# The Histogram of Accecptance rate 
hist(estep$ar, xlim =c(0,1));abline(v = 0.44);

# Chain of the First Subject
plot(gamma[1:M], type= 'l')

# The autocorrelation of the chain in the First Subject
acf(gamma[1:M])
```

+ Conclusion: The acceptance rates for each subjects are between 25% and 50%. When using $N(0,\sigma^2 =0.25^2)$ distribution, it was more likely to have the acceptance rates close to 44%. However, there are many acceptance rates greater than 50%. The line graph of the chain for the first subject and the graph of autocorrelation looks good. 